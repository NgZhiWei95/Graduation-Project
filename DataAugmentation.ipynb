{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_TM-1-Ld279R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M7dn_LGxd5MF"
      },
      "outputs": [],
      "source": [
        "#Data augmentation for training dataset\n",
        "\n",
        "#Imports\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Forged\n",
        "\n",
        "#Use Tensorflow's ImageDataGenerator for data augmentation\n",
        "dataGenerator = ImageDataGenerator(        \n",
        "            rotation_range = 90,\n",
        "            width_shift_range = 0.5,  \n",
        "            height_shift_range = 0.1,            \n",
        "            zoom_range = 0.15,        \n",
        "            vertical_flip = True,         \n",
        "            fill_mode = 'nearest')\n",
        "\n",
        "#Forged training set directory, set images size, and declare dataset array\n",
        "directory = '/content/drive/MyDrive/SignatureDataSet(jpg)/training/forged/'\n",
        "imgSize = 256\n",
        "datasetArray = []\n",
        "\n",
        "#Take in each images, resize it, and put it into dataset array\n",
        "my_images = os.listdir(directory)\n",
        "for i, image_name in enumerate(my_images):    \n",
        "   if (image_name.split('.')[1] == 'jpg'):        \n",
        "       image = io.imread(directory + image_name)        \n",
        "       image = Image.fromarray(image, 'RGB')        \n",
        "       image = image.resize((imgSize,imgSize)) \n",
        "       datasetArray.append(np.array(image))\n",
        "\n",
        "#By ImageDataGenerator, create 2 new images for each forged training image\n",
        "x = np.array(datasetArray)\n",
        "i = 0\n",
        "for batch in dataGenerator.flow(x, batch_size = 2,\n",
        "                          save_to_dir = '/content/drive/MyDrive/forgery/',\n",
        "                          save_prefix = 'aug',\n",
        "                          save_format = 'png'):\n",
        "    i = i + 1\n",
        "    if i > 119:\n",
        "        break"
      ],
      "metadata": {
        "id": "FSqGK5SIeEJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Tensorflow's ImageDataGenerator for data augmentation\n",
        "dataGenerator = ImageDataGenerator(        \n",
        "            rotation_range = 180,\n",
        "            width_shift_range = 0.24,  \n",
        "            height_shift_range = 0.12,            \n",
        "            zoom_range = 0.11,        \n",
        "            horizontal_flip = True,         \n",
        "            fill_mode = 'wrap')\n",
        "\n",
        "#Forged training set directory, set images size, and declare dataset array\n",
        "directory = '/content/drive/MyDrive/forged/'\n",
        "imgSize = 256\n",
        "datasetArray = []\n",
        "\n",
        "#Take in each images, resize it, and put it into dataset array\n",
        "my_images = os.listdir(directory)\n",
        "for i, image_name in enumerate(my_images):    \n",
        "   if (image_name.split('.')[1] == 'jpg'):        \n",
        "       image = io.imread(directory + image_name)        \n",
        "       image = Image.fromarray(image, 'RGB')        \n",
        "       image = image.resize((imgSize,imgSize)) \n",
        "       datasetArray.append(np.array(image))\n",
        "\n",
        "#By ImageDataGenerator, create 2 new images for each forged training image\n",
        "x = np.array(datasetArray)\n",
        "i = 0\n",
        "for batch in dataGenerator.flow(x, batch_size = 5,\n",
        "                          save_to_dir = '/content/drive/MyDrive/forgery/',\n",
        "                          save_prefix = 'dataAug',\n",
        "                          save_format = 'png'):\n",
        "    i = i + 1\n",
        "    if i > 119:\n",
        "        break"
      ],
      "metadata": {
        "id": "n8z6L5gA2Zx6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Genuine\n",
        "\n",
        "#Use Tensorflow's ImageDataGenerator for data augmentation\n",
        "dataGenerator = ImageDataGenerator(        \n",
        "            rotation_range = 30,\n",
        "            width_shift_range = 0.2,  \n",
        "            height_shift_range = 0.4,            \n",
        "            zoom_range = 0.25,        \n",
        "            vertical_flip = True,         \n",
        "            fill_mode = 'reflect')\n",
        "\n",
        "#Genuine training set directory, set images size, and declare dataset array\n",
        "directory = '/content/drive/MyDrive/SignatureDataSet(jpg)/training/genuine/'\n",
        "imgSize = 256\n",
        "datasetArray = []\n",
        "\n",
        "#Take in each images, resize it, and put it into dataset array\n",
        "my_images = os.listdir(directory)\n",
        "for i, image_name in enumerate(my_images):    \n",
        "   if (image_name.split('.')[1] == 'jpg'):        \n",
        "       image = io.imread(directory + image_name)        \n",
        "       image = Image.fromarray(image, 'RGB')        \n",
        "       image = image.resize((imgSize,imgSize)) \n",
        "       datasetArray.append(np.array(image))\n",
        "\n",
        "#By ImageDataGenerator, create 2 new images for each genuine training image\n",
        "x = np.array(datasetArray)\n",
        "i = 0\n",
        "for batch in dataGenerator.flow(x, batch_size = 2,\n",
        "                          save_to_dir = '/content/drive/MyDrive/genuine/',\n",
        "                          save_prefix = 'aug',\n",
        "                          save_format = 'png'):\n",
        "    i = i + 1\n",
        "    if i > 119:\n",
        "        break"
      ],
      "metadata": {
        "id": "nHJXEaNJmoeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Tensorflow's ImageDataGenerator for data augmentation\n",
        "dataGenerator = ImageDataGenerator(        \n",
        "            rotation_range = 270,\n",
        "            width_shift_range = 0.35,  \n",
        "            height_shift_range = 0.13,            \n",
        "            zoom_range = 0.34,        \n",
        "            horizontal_flip = True,         \n",
        "            fill_mode = 'wrap')\n",
        "\n",
        "#Genuine training set directory, set images size, and declare dataset array\n",
        "directory = '/content/drive/MyDrive/training/genuine/'\n",
        "imgSize = 256\n",
        "datasetArray = []\n",
        "\n",
        "#Take in each images, resize it, and put it into dataset array\n",
        "my_images = os.listdir(directory)\n",
        "for i, image_name in enumerate(my_images):    \n",
        "   if (image_name.split('.')[1] == 'jpg'):        \n",
        "       image = io.imread(directory + image_name)        \n",
        "       image = Image.fromarray(image, 'RGB')        \n",
        "       image = image.resize((imgSize,imgSize)) \n",
        "       datasetArray.append(np.array(image))\n",
        "\n",
        "#By ImageDataGenerator, create 2 new images for each genuine training image\n",
        "x = np.array(datasetArray)\n",
        "i = 0\n",
        "for batch in dataGenerator.flow(x, batch_size = 5,\n",
        "                          save_to_dir = '/content/drive/MyDrive/genuine/',\n",
        "                          save_prefix = 'dataAug',\n",
        "                          save_format = 'png'):\n",
        "    i = i + 1\n",
        "    if i > 119:\n",
        "        break"
      ],
      "metadata": {
        "id": "dLp2hQeR3gr9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}